<!DOCTYPE html>
<html lang="en">

<head>
    <meta name="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="Stephen Panaro">
    <meta name="keywords" content="Stephen Panaro, blog">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <a rel="me" href="https://mastodon.social/@smpanaro"></a>
    <link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Atom" />
    <meta property="og:type" content="website">
    <meta property="og:title" content="blog">
    <title>stephenpanaro.com - blog</title>

    <style>
        body {
            font-family: -apple-system, serif, Arial, Helvetica, sans-serif;
        }

        @media (prefers-color-scheme: dark) {
            body {
                background-color: #191919;
                color: #f6f6f6;
            }
        }

        a {
            color: unset;
        }

        a.post {
            display: block;
            margin-top: 8px;
        }

        header h2 {
            margin-bottom: 0;
        }

        header div {
            display: flex;
            gap: 8px;
        }

        p {
            max-width: 400px;
            margin: 4px 0;
            opacity: 0.6;
            font-style: italic;
            font-size: 12px;
            font-weight: 200;
            padding: 0;
        }
    </style>
</head>

<body>
    <header>
        <h2>stephen &bull; blog</h2>
        <div>
            <a href="/">home</a>
            <a href="/feed.xml">rss</a>
        </div>
    </header>

    <article>
        <h2>posts</h2>
        <a class="post" href="/blog/inside-apples-2023-transformers">
            Inside Apple's 2023 Transformer Models
        </a>
        <p>What can we learn from them?</p>
        <a class="post" href="/blog/time-series-compression">
            No Frills Time Series Compression That Also Works
        </a>
        <p>So you have some time series data and you want to make it smaller?</p>
        <a class="post" href="/blog/llm-quantization-for-iphone">
            LLMs for your iPhone: Whole-Tensor 4 Bit Quantization
        </a>
        <p>Shrinking models for Apple Silicon</p>
    </article>


</body>

</html>